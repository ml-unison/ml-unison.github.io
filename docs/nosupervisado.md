---
title: Aprendizaje no supervisado 
subtitle: Curso Reconocimiento de Patrones LCC/UNISON
layout: page
hero_image: https://github.com/ml-unison/ml-unison.github.io/raw/main/docs/img/alt-banner.jpg
hero_darken: true
show_sidebar: false
---

## Aprendizaje no supervisado 

1. [Una modesta presentación sobre análisis aglomerativo](https://github.com/mcd-unison/aaa-curso/raw/main/slides/clustering.pdf) que hice yo y me quedo medio feyuya.

2. [Una presentación general](https://www.mit.edu/~9.54/fall14/slides/Class13.pdf) de Ullman y colaboradores para un curso del MIT.
   
3. [Una presentación de 2 algoritmos clásicos de aprendizaje no supervisado](http://www.cs.rpi.edu/~magdon/courses/LFD-Slides/SlidesLect19.pdf) de M. Magdon-Ismail.

4. [Una libreta muy completa sobre el uso y aplicación de varios algoritmos de clustering incluidos en *scikit-learn*](https://colab.research.google.com/github/ageron/handson-ml3/blob/main/09_unsupervised_learning.ipynb). Le dedica mucho espacio a explicar todos los pasos de las *K-medias* y sus variantes, pero es muy claro y muy completo.


## Análisis en componentes principales

1. [Notas sobre PCA](https://github.com/mcd-unison/ing-caract/raw/main/pdf/PCA-Standford.pdf) del curso de Andrew Ng en Stanford

2. [Principal Component Analysis](https://colab.research.google.com/github/jakevdp/PythonDataScienceHandbook/blob/master/notebooks/05.09-Principal-Component-Analysis.ipynb). Libreta de Colab del libro [Python Data Science Handbook](https://jakevdp.github.io/PythonDataScienceHandbook/)

## Aprendizaje en variedades para visualización de datos de alta dimensionalidad

1. [*Manifold learning*](https://scikit-learn.org/stable/modules/manifold.html) en `sci-kit learn`

1. [Libreta de colab sobre *Manifold Learning*](https://colab.research.google.com/github/jakevdp/PythonDataScienceHandbook/blob/master/notebooks/05.10-Manifold-Learning.ipynb) del libro [Python Data Science Handbook](https://jakevdp.github.io/PythonDataScienceHandbook/)

2. El algoritmo más conocido [*t-distributed stochastic neighbor embedding (t-SNE)*](https://www.jmlr.org/papers/volume9/vandermaaten08a/vandermaaten08a.pdf), con una [explicación clara del algoritmo](https://www.oreilly.com/content/an-illustrated-introduction-to-the-t-sne-algorithm/) y un [muy bonito artículo interactivo para entender como hace las separaciones el método de *t-SNE*](https://distill.pub/2016/misread-tsne/)

3. [Un curso de *Manifold Learning*](https://github.com/drewwilimitis/Manifold-Learning) a partir de libretas *jupyter*

4. El metodo de moda [*Uniform Manifold Aproximation Proyection (UMAP)*](https://arxiv.org/pdf/1802.03426.pdf) y el [enlace a la librería en python con ejemplos de aplicación](https://umap-learn.readthedocs.io/en/latest/index.html)


