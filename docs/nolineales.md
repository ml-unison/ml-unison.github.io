---
title: Modelos no lineales de aprendizaje 
subtitle: Curso Reconocimiento de Patrones LCC/UNISON
layout: page
hero_image: https://github.com/ml-unison/ml-unison.github.io/raw/main/docs/img/alt-banner.jpg
hero_darken: true
show_sidebar: false
---


## Árboles de decisión

1. [Presentación](https://people.csail.mit.edu/dsontag/courses/ml16/slides/lecture11.pdf) de David Sontag (NYU) sobre árboles de decisión y bosques aleatorios.

2. [Un reporte de Quinlan](https://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.18.4267&rep=rep1&type=pdf) de 1986 con algunas técnicas para reducir el error en árboles de decisión usando *post-poda*.

## Modelos de *ensemble*

1. [Presentación](https://scholar.princeton.edu/sites/default/files/bstewart/files/boosting.pdf) de J. Cohen (Princeton) sobre *boosting*, que cubre los métodos de *Adaboost* y *Gradient boosting trees*. Para el algoritmo de *Gradient Boosting* aqui dejamos una [presentación](https://www.ccs.neu.edu/home/vip/teach/MLcourse/4_boosting/slides/gradient_boosting.pdf) más clara de las ideas originales.

2. La librería [XGboost](https://xgboost.ai) soportada ppr NVidia e Intel, la más popular para *Gradient Boosting*. Tambié la librería [LightGBM](https://lightgbm.readthedocs.io), desarrollada por Microsoft es muy utilizada, así como [CatBoost](https://catboost.ai), desarrollada por Yandex.

3. Una [presentación](https://www.cs.ubc.ca/~lowe/425/slides/13-ViolaJones.pdf) del famoso algoritmo de Viola-Jones, y una [presentación](https://www.google.com/url?sa=t&rct=j&q=&esrc=s&source=web&cd=&cad=rja&uact=8&ved=2a[…]a-Jones%2520presentation.ppt&usg=AOvVaw0XtfrKMk_OnA9HawvyZ6vI) hecha por los autores del algoritmo.
   
4. El [artículo original](https://github.com/mcd-unison/aaa-curso/raw/main/pdf/grad_boost_original.pdf) sobre *gradient boosting*, y un artículo más reciente sobre la teoría y la práctica [de este tipo de algoritmos de *ensemble*](https://github.com/mcd-unison/aaa-curso/raw/main/pdf/boosting_TyA.pdf)
   
## Otros modelos de aprendizaje

1. K Vecinos próximos. [Una presentación de D. Sontag de la NYU](https://github.com/mcd-unison/aaa-curso/raw/main/slides/knn-ny.pdf) y [otra presentación de M Kang de la UNLV](https://mkang.faculty.unlv.edu/teaching/CS489_689/05.KNN.pdf)